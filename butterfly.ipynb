{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNA3JQdMiGPVm9hSv5bRRtI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/auchanda/machinelearning/blob/main/butterfly.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0GC_iDSiJiaC"
      },
      "outputs": [],
      "source": [
        "#!/usr/bin/env python\n",
        "# coding: utf-8\n",
        "\n",
        "# In[ ]:\n",
        "\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2 as cv\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "\n",
        "# In[ ]:\n",
        "\n",
        "\n",
        "df_train = pd.read_csv(\"/content/drive/MyDrive/mlearn/dataset/butterfly/Training_set.csv\")\n",
        "df_test = pd.read_csv(\"/content/drive/MyDrive/mlearn/dataset/butterfly/Testing_set.csv\")\n",
        "df_train.sample(10)\n",
        "#!/usr/bin/env python\n",
        "# coding: utf-8\n",
        "\n",
        "# In[ ]:\n",
        "\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2 as cv\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "\n",
        "# In[ ]:\n",
        "\n",
        "\n",
        "df_train = pd.read_csv(\"/content/drive/MyDrive/mlearn/dataset/butterfly/Training_set.csv\")\n",
        "df_test = pd.read_csv(\"/content/drive/MyDrive/mlearn/dataset/butterfly/Testing_set.csv\")\n",
        "df_train.sample(10)\n",
        "\n",
        "\n",
        "# In[ ]:\n",
        "\n",
        "\n",
        "df_test.head()\n",
        "\n",
        "\n",
        "# In[9]:\n",
        "\n",
        "\n",
        "df_train.info(),df_train.shape\n",
        "\n",
        "\n",
        "# In[10]:\n",
        "\n",
        "\n",
        "df_test.info(),df_test.shape\n",
        "\n",
        "\n",
        "# In[14]:\n",
        "\n",
        "\n",
        "df = pd.concat([df_train[['filename']],df_test[['filename']]],axis='rows')\n",
        "df['label'] = [1]*len(df)\n",
        "df.sample(10)\n",
        "\n",
        "\n",
        "# In[18]:\n",
        "\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "encoder = LabelEncoder()\n",
        "df_train['label_en'] = encoder.fit_transform(df_train['label'])\n",
        "df_train.sample(3)\n",
        "\n",
        "\n",
        "# In[ ]:\n",
        "\n",
        "\n",
        "# adding non butterfly images\n",
        "non_target = []\n",
        "MAIN_FILE = \"/content/drive/MyDrive/mlearn/dataset/butterfly/train\"\n",
        "for img in os.listdir(MAIN_FILE):\n",
        "    non_target.append(img)\n",
        "\n",
        "\n",
        "# In[ ]:\n",
        "\n",
        "\n",
        "non_target\n",
        "\n",
        "\n",
        "# In[ ]:\n",
        "\n",
        "\n",
        "non_target_labels = np.c_[non_target,[0]*len(non_target)]\n",
        "non_df = pd.DataFrame(non_target_labels,columns=['filename','label'])\n",
        "non_df.head()\n",
        "\n",
        "\n",
        "# In[ ]:\n",
        "\n",
        "\n",
        "# imbalanced data visualization\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "P = len(df)\n",
        "N = len(non_df)\n",
        "\n",
        "layout = go.Layout(\n",
        "    title='Imbalanced data'\n",
        ")\n",
        "def plot_pie_chart(labels, values):\n",
        "    fig = go.Figure(data=[go.Pie(labels=labels, values=values)])\n",
        "    fig.show()\n",
        "\n",
        "labels = ['positive', 'Negative']\n",
        "values = [P,N]\n",
        "plot_pie_chart(labels, values)\n",
        "\n",
        "\n",
        "# In[ ]:\n",
        "\n",
        "\n",
        "#Augmentation\n",
        "from matplotlib import image as mpimg\n",
        "non_target = []\n",
        "IMAGE_SIZE = (40,40)\n",
        "for img in non_df['filename']:\n",
        "\n",
        "    img = cv.imread(\"/content/drive/MyDrive/mlearn/dataset/butterfly/train/\"+img)\n",
        "    img = cv.resize(img,IMAGE_SIZE)\n",
        "    non_target.append(img/255.0)\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Create an instance of the ImageDataGenerator class\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=30,  # Randomly rotate images by 30 degrees\n",
        "    width_shift_range=0.2,  # Randomly shift images horizontally by 20% of the total width\n",
        "    height_shift_range=0.2,  # Randomly shift images vertically by 20% of the total height\n",
        "    shear_range=0.3,  # Apply shear transformation with a shear angle of 30 degrees\n",
        "    zoom_range=0.3,  # Randomly zoom images by up to 30%\n",
        "    horizontal_flip=True,  # Randomly flip images horizontally\n",
        "    vertical_flip=False  # Do not perform vertical flips\n",
        ")\n",
        "\n",
        "# Example grayscale numpy array of images (3D)\n",
        "images = non_target # Shape: (num_samples, height, width)\n",
        "\n",
        "# Generate augmented grayscale images\n",
        "augmented_images = []\n",
        "\n",
        "for image in images:\n",
        "    num_generated_images = 0\n",
        "\n",
        "    while num_generated_images < 60:\n",
        "        augmented_image = datagen.random_transform(image)\n",
        "        augmented_images.append(augmented_image)\n",
        "        num_generated_images += 1\n",
        "# Convert augmented grayscale images back to a NumPy array\n",
        "augmented_images = np.array(augmented_images)\n",
        "non_target = np.squeeze(augmented_images)\n",
        "print(non_target.shape)\n",
        "plt.imshow(non_target[0])\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# In[ ]:\n",
        "\n",
        "\n",
        "plt.imshow(non_target[1])\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# In[14]:\n",
        "\n",
        "\n",
        "IMAGE_SIZE = (40,40)\n",
        "IMAGE_SIZE_CLASS = (60,60)\n",
        "\n",
        "train = []\n",
        "\n",
        "# it is for classification model which we will se after detection process\n",
        "train_class = []\n",
        "train_labels = []\n",
        "\n",
        "test = []\n",
        "print(\"starting\")\n",
        "\n",
        "for img,label in zip(df_train['filename'],df_train['label_en']):\n",
        "    img = cv.imread(\"/content/drive/MyDrive/mlearn/dataset/butterfly/train/\"+img)\n",
        "    det = cv.resize(img,IMAGE_SIZE)\n",
        "    clas = cv.resize(img,IMAGE_SIZE_CLASS)\n",
        "    train.append(det/255.0)\n",
        "    train_class.append(clas/255.0)\n",
        "    train_labels.append(label)\n",
        "\n",
        "\n",
        "for img in df_test['filename']:\n",
        "    img = cv.imread(\"/content/drive/MyDrive/mlearn/dataset/butterfly/train/\"+img)\n",
        "    img = cv.resize(img,IMAGE_SIZE)\n",
        "    test.append(img/255.0)\n",
        "\n",
        "plt.imshow(train[0])\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# In[23]:\n",
        "\n",
        "\n",
        "images = list(train)+list(test)\n",
        "\n",
        "# Generate augmented images\n",
        "augmented_images_target = []\n",
        "count=0\n",
        "print(\"Started..\")\n",
        "for image in images:\n",
        "    num_generated_images = 0\n",
        "    print(\"image -\",count)\n",
        "    count=count+1\n",
        "    while num_generated_images < 6:\n",
        "        print(\"going..\")\n",
        "        augmented_image = datagen.random_transform(image)\n",
        "        augmented_images_target.append(augmented_image)\n",
        "        num_generated_images += 1\n",
        "\n",
        "augmented_images_target = np.array(augmented_images_target)\n",
        "target = np.squeeze(augmented_images_target)\n",
        "print(\"Ended\")\n",
        "print(target.shape)\n",
        "\n",
        "P = len(target)\n",
        "N = len(non_target)\n",
        "\n",
        "layout = go.Layout(\n",
        "    title='Balanced data'\n",
        ")\n",
        "def plot_pie_chart(labels, values):\n",
        "    fig = go.Figure(data=[go.Pie(labels=labels, values=values)],layout=layout)\n",
        "    fig.show()\n",
        "\n",
        "labels = ['positive', 'Negative']\n",
        "values = [P,N]\n",
        "plot_pie_chart(labels, values)\n",
        "\n",
        "\n",
        "# In[24]:\n",
        "\n",
        "\n",
        "X = np.array(list(target)+list(non_target))\n",
        "y = np.array([1]*len(target)+[0]*len(list(non_target)))\n",
        "\n",
        "X.shape,y.shape\n",
        "\n",
        "\n",
        "# In[25]:\n",
        "\n",
        "\n",
        "# training and testing data spliting\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,y_train,y_test = train_test_split(X,y,stratify=y)\n",
        "X_train.shape,X_test.shape,y_train.shape,y_test.shape\n",
        "\n",
        "\n",
        "# In[26]:\n",
        "\n",
        "\n",
        "# Building CNN\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "\n",
        "# In[27]:\n",
        "\n",
        "\n",
        "# Define the CNN model\n",
        "model = keras.Sequential()\n",
        "model.add(keras.layers.Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(40, 40, 3)))\n",
        "model.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(keras.layers.Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(keras.layers.Flatten())\n",
        "model.add(keras.layers.Dense(64, activation='relu'))\n",
        "model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=6, batch_size=32)\n",
        "\n",
        "\n",
        "# In[28]:\n",
        "\n",
        "\n",
        "model.evaluate(X_test,y_test)\n",
        "\n",
        "\n",
        "# In[29]:\n",
        "\n",
        "\n",
        "tensors = tf.convert_to_tensor(np.array(X_test))\n",
        "probabilities = model.predict(tensors)\n",
        "threshold = 0.5\n",
        "y_pred = (probabilities > threshold).astype(int)[:,0]\n",
        "y_pred\n",
        "\n",
        "\n",
        "# In[30]:\n",
        "\n",
        "\n",
        "import plotly.graph_objects as go\n",
        "from sklearn.metrics import confusion_matrix,classification_report\n",
        "from seaborn import heatmap as hm\n",
        "\n",
        "cm = confusion_matrix(y_test,y_pred)\n",
        "hm(cm,annot=True,fmt='')\n",
        "plt.xlabel(\"preidcte\")\n",
        "plt.ylabel(\"actual\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# In[31]:\n",
        "\n",
        "\n",
        "cr = classification_report(y_test,y_pred)\n",
        "print(cr)\n",
        "\n",
        "\n",
        "# In[32]:\n",
        "\n",
        "\n",
        "#spliting images for classification\n",
        "\n",
        "train_class_np = np.array(train_class)\n",
        "labels_np = np.array(train_labels)\n",
        "\n",
        "X_train,X_test,y_train,y_test = train_test_split(train_class_np,labels_np,stratify=labels_np)\n",
        "X_train.shape,X_test.shape,y_train.shape,y_test.shape\n",
        "\n",
        "\n",
        "# In[33]:\n",
        "\n",
        "\n",
        "# Define the CNN model\n",
        "model_classification = keras.Sequential()\n",
        "model_classification.add(keras.layers.Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(60, 60, 3)))\n",
        "model_classification.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "model_classification.add(keras.layers.Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
        "model_classification.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "model_classification.add(keras.layers.Flatten())\n",
        "model_classification.add(keras.layers.Dense(64, activation='relu'))\n",
        "model_classification.add(keras.layers.Dense(len(np.unique(labels_np)), activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model_classification.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model_classification.fit(X_train, y_train, epochs=6, batch_size=32)\n",
        "\n",
        "\n",
        "# In[34]:\n",
        "\n",
        "\n",
        "model_classification.evaluate(X_test,y_test)\n",
        "\n",
        "\n",
        "# In[35]:\n",
        "\n",
        "\n",
        "probabilities = model_classification.predict(np.array(X_test))\n",
        "y_pred = [np.argmax(img) for img in probabilities]\n",
        "print(y_pred)\n",
        "\n",
        "\n",
        "# In[36]:\n",
        "\n",
        "\n",
        "probabilities = model_classification.predict(np.array([X_test[2]]))\n",
        "probabilities\n",
        "\n",
        "\n",
        "# In[ ]:\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b94CigoaPglr",
        "outputId": "0741b76d-5106-49e5-b64e-a8ee7be52e39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    }
  ]
}